{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medigraph.data.abide import DEFAULT_ABIDE_LOCATION, AbideData\n",
    "from medigraph.data.io import Dump\n",
    "import numpy as np\n",
    "from nilearn import plotting\n",
    "from medigraph.model.gcn import GCN\n",
    "from medigraph.model.baseline import DenseNN\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = AbideData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check connectivy matrix for a single patient\n",
    "- 111x111 matrices\n",
    "- We'll retrieve the $6216=\\frac{111*(111+1)}{2}$ raw coefficients from the upper triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the connectivity matrix for the first subject\n",
    "idx = 0\n",
    "mat = dat.get_connectivity_matrix(idx)\n",
    "plotting.plot_matrix(\n",
    "    mat,\n",
    "    figure=(6, 6),\n",
    "    vmax=1,\n",
    "    vmin=0,\n",
    "    title=f\"Patient {idx} connectivity matrix {mat.shape}\"\n",
    ")\n",
    "feature_vector_input = dat.get_connectivity_features(idx)\n",
    "print(f\"input feature vector shape: {feature_vector_input.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classifier\n",
    "### Build adjacency, features matrix and classification labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Build adjacency matrix and input feature vectors\n",
    "inp_np, lab_np, adj_np = dat.get_training_data()\n",
    "print(f\"Adjacency matrix : {adj_np.shape} [VxV]\")\n",
    "print(f\"Labels {lab_np.shape} : [V]\")\n",
    "print(f\"Input feature vector {inp_np.shape} : [VxF]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Load data to GPU\n",
    "labels_np = dat.get_labels()\n",
    "adj = torch.tensor(adj_np, dtype=torch.float32).to(device)\n",
    "inp = torch.tensor(inp_np, dtype=torch.float32).to(device)\n",
    "lab = torch.tensor(labels_np, dtype=torch.float32).to(device) # for binary classification\n",
    "inp.shape, adj.shape, lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Train \n",
    "N_EPOCHS = 1000\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "training_losses_dict = {}\n",
    "training_accuracy_dict = {}\n",
    "for model_name in [\"GCN\", \"Dense\"]:\n",
    "    if model_name == \"GCN\":\n",
    "        model = GCN(inp.shape[1], adj, hdim=64)\n",
    "    else:\n",
    "        model = DenseNN(inp.shape[1], hdim=64)\n",
    "    model.to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1.E-3, weight_decay=0.1) #\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "    for ep in tqdm(range(N_EPOCHS)):\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        logit = model(inp)\n",
    "        loss = criterion(logit, lab)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        with torch.no_grad(): \n",
    "            predicted_prob = torch.sigmoid(logit).squeeze()  # Apply sigmoid and remove extra dimensions if any\n",
    "            predicted = (predicted_prob >= 0.5).long()  # Convert probabilities to 0 or 1\n",
    "            correct = (predicted == lab).sum().item()\n",
    "            total = lab.shape[0]\n",
    "            accuracy = correct / total\n",
    "            training_accuracies.append(accuracy)\n",
    "        if ep % 100 == 0:\n",
    "            print(f\"Epoch {ep} loss: {loss.item():10f} - accuracy: {accuracy:.2%}\") \n",
    "        training_losses.append(loss.detach().cpu())\n",
    "    training_losses_dict[model_name] = training_losses\n",
    "    training_accuracy_dict[model_name] = training_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "for model_name, training_losses in training_losses_dict.items():\n",
    "    axs[0].plot(training_losses, label=model_name)\n",
    "    axs[1].plot(training_accuracy_dict[model_name], label=f\"{model_name} accuracy\")\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "axs[0].set_title(\"Training loss (Binary Cross Entropy)\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
