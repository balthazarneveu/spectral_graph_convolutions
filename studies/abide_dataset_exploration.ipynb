{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medigraph.data.abide import AbideData\n",
    "import numpy as np\n",
    "from nilearn import plotting\n",
    "from medigraph.model.gcn import GCN, SparseGCN\n",
    "from medigraph.model.baseline import DenseNN\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from medigraph.data.preprocess import sanitize_data, visual_sanity_check_input, whiten\n",
    "from medigraph.train import training_loop, train, plot_learning_curves, test\n",
    "from medigraph.data.properties import INPUTS, LABELS, TRAIN_MASK, VAL_MASK, TEST_MASK\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = AbideData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check connectivy matrix for a single patient\n",
    "- 111x111 matrices\n",
    "- We'll retrieve the $6216=\\frac{111*(111+1)}{2}$ raw coefficients from the upper triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the connectivity matrix for the first subject\n",
    "idx = 0\n",
    "mat = dat.get_connectivity_matrix(idx)\n",
    "plotting.plot_matrix(\n",
    "    mat,\n",
    "    figure=(6, 6),\n",
    "    vmax=1,\n",
    "    vmin=0,\n",
    "    title=f\"Patient {idx} connectivity matrix {mat.shape}\"\n",
    ")\n",
    "feature_vector_input = dat.get_connectivity_features(idx)\n",
    "print(f\"input feature vector shape: {feature_vector_input.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classifier\n",
    "### Build adjacency, features matrix and classification labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Build adjacency matrix and input feature vectors\n",
    "inp_np, lab_np, adj_np = dat.get_training_data()\n",
    "print(f\"Adjacency matrix : {adj_np.shape} [VxV]\")\n",
    "print(f\"Labels {lab_np.shape} : [V]\")\n",
    "print(f\"Input feature vector {inp_np.shape} : [VxF]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Load data to GPU\n",
    "labels_np = dat.get_labels()\n",
    "adj = torch.tensor(adj_np, dtype=torch.float32).to(device)\n",
    "inp_raw = torch.tensor(inp_np, dtype=torch.float32).to(device)  # [V=871,  F6216]\n",
    "lab = torch.tensor(labels_np, dtype=torch.float32).to(device)  # for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Sanitize and whiten data\n",
    "clean_inp = sanitize_data(inp_raw)\n",
    "inp = whiten(clean_inp)\n",
    "inp.shape, adj.shape, lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Visalization of sanity check\n",
    "visual_sanity_check_input(inp_raw)\n",
    "visual_sanity_check_input(clean_inp)\n",
    "visual_sanity_check_input(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % sanity check on graph adjacency matrix\n",
    "model = GCN(inp.shape[1], adj, hdim=64)\n",
    "plotting.plot_matrix(\n",
    "    model.adj.detach().cpu().numpy(),\n",
    "    figure=(6, 6),\n",
    "    vmax=0.005,\n",
    "    vmin=0,\n",
    "    title=f\"Graph normalized adjacency matrix {mat.shape}\"\n",
    ")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {\n",
    "    INPUTS: inp,\n",
    "    LABELS: lab\n",
    "}\n",
    "metric_dict = {}\n",
    "for model_name in [\"Dense\", \"GCN\"]:\n",
    "    if model_name == \"GCN\":\n",
    "        model = GCN(inp.shape[1], adj, hdim=64)\n",
    "    else:\n",
    "        model = DenseNN(inp.shape[1], hdim=64)\n",
    "    model.to(device)\n",
    "\n",
    "    model, metrics = training_loop(model, training_data, device, n_epochs=1000)\n",
    "    metric_dict[model_name] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metric_dict: dict):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "    for model_name, metric in metric_dict.items():\n",
    "        print(metric.keys())\n",
    "        axs[0].plot(metric[\"training_losses\"], label=model_name)\n",
    "        axs[1].plot(metric[\"training_accuracies\"], label=f\"{model_name} accuracy\")\n",
    "    for ax in axs:\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "    axs[0].set_title(\"Training loss (Binary Cross Entropy)\")\n",
    "    axs[1].set_title(\"Accuracy\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_metrics(metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GCN based on kipf github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lab, adj = dat.get_training_data()\n",
    "print(f\"Adjacency matrix : {adj.shape} [VxV]\")\n",
    "print(f\"Labels {lab.shape} : [V]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SparseGCN(inp.shape[1], nhid=16, nclass=2, adjacency=adj)\n",
    "adj_mat = model.adj.to_dense().cpu().numpy()\n",
    "plotting.plot_matrix(\n",
    "    adj_mat,\n",
    "    figure=(6, 6),\n",
    "    vmax=0.005,\n",
    "    vmin=0,\n",
    "    title=f\"Graph normalized adjacency matrix {adj_mat.shape}\"\n",
    ")\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_training_dict(data : AbideData, device: torch.device = device,\n",
    "             nb_train: int = 600, \n",
    "             nb_val: int = 100):\n",
    "\n",
    "    graph_signals, node_labels, adj = data.get_training_data()  \n",
    "\n",
    "    inp = torch.tensor(graph_signals, dtype=torch.float32).to(device)\n",
    "    labels = torch.tensor(node_labels, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "    clean_inp = sanitize_data(inp)\n",
    "    inp = whiten(clean_inp)\n",
    "\n",
    "    # get random masks\n",
    "    shuffle_nodes = np.random.permutation(range(inp.shape[0]))\n",
    "    train_mask = shuffle_nodes[:nb_train]\n",
    "    val_mask = shuffle_nodes[nb_train:nb_train+nb_val]\n",
    "    test_mask = shuffle_nodes[nb_train+nb_val:]\n",
    "\n",
    "    train_mask = torch.LongTensor(train_mask) #int64 tensor\n",
    "    val_mask = torch.LongTensor(val_mask)\n",
    "    test_mask = torch.LongTensor(test_mask)\n",
    "\n",
    "    return { INPUTS : inp,\n",
    "            LABELS : labels,\n",
    "            TRAIN_MASK : train_mask,\n",
    "            VAL_MASK : val_mask,\n",
    "            TEST_MASK : test_mask\n",
    "            }, adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dict, graph_adj = get_training_dict(dat, nb_train=500, nb_val=200)\n",
    "model_GCN1 = SparseGCN(training_dict[INPUTS].shape[1], \n",
    "                  nhid=64, \n",
    "                  nclass=1, \n",
    "                  adjacency=graph_adj, proba_dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_GCN, train_log, val_log = train(model_GCN1, training_dict, \n",
    "                                              nEpochs=400, \n",
    "                                              optimizer_params={'lr': 0.01, 'weight_decay': 0.05})\n",
    "torch.save(trained_model_GCN.state_dict(), \"__trained_model_GCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(train_log, val_log, title=\"Training of model_GCN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing \n",
    "loss_test, acc_test = test(trained_model_GCN, training_dict)\n",
    "print(f\"Test loss: {loss_test.item():.4f}, Test accuracy: {acc_test.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train bigger model\n",
    "\n",
    "model_GCN2 = SparseGCN(\n",
    "    training_dict[INPUTS].shape[1],\n",
    "    nhid=[2048, 512, 32],\n",
    "    nclass=1,\n",
    "    adjacency=adj,\n",
    ")\n",
    "\n",
    "trained_model_GCN2, train_log2, val_log2 = train(model_GCN2, training_dict,\n",
    "                                                 nEpochs=200,\n",
    "                                                 optimizer_params={'lr': 0.001, 'weight_decay': 0.001})\n",
    "\n",
    "plot_learning_curves(train_log2, val_log2, title=\"Training of model_GCN2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing \n",
    "loss_test, acc_test = test(trained_model_GCN2, training_dict)\n",
    "print(f\"Test loss: {loss_test.item():.4f}, Test accuracy: {acc_test.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
